{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cmx\n",
    "import matplotlib.colors as colors\n",
    "import math\n",
    "import pylab\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "#from textblob import TextBlob\n",
    "%matplotlib inline\n",
    "\n",
    "# import some additional libraries from sklearn\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn import datasets, linear_model, metrics \n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# Documentation for SKLearn Linear Regression: \n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAN FRANCISCO and NYC DATA\n",
    "data_sf = pd.read_csv(\"x+income+commute+sentiment+poverty_sf.csv\", low_memory=False)\n",
    "data_nyc = pd.read_csv(\"x+income+commute+sentiment+poverty.csv\", low_memory=False)\n",
    "\n",
    "# data_sf = pd.read_csv(\"ny_listings_full_clean.csv\", low_memory=False)\n",
    "# data_nyc = pd.read_csv(\"sf_listings_full_clean.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sf = np.log( data_sf['price'].copy() )\n",
    "y_nyc = np.log( data_nyc['price'].copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'property_type'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2656\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2657\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2658\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'property_type'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-effb1f852401>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# encode SF categorical variables\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mproperty_dummies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_sf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'property_type'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mroom_dummies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_sf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'room_type'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mbed_dummies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_sf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'bed_type'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2925\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2926\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2927\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2928\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2929\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2657\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2658\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2659\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2660\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2661\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'property_type'"
     ]
    }
   ],
   "source": [
    "\n",
    "# encode SF categorical variables\n",
    "property_dummies = pd.get_dummies(data_sf['property_type'])\n",
    "room_dummies = pd.get_dummies(data_sf['room_type'])\n",
    "bed_dummies = pd.get_dummies(data_sf['bed_type'])\n",
    "ratings_scores_dummies = pd.get_dummies(data_sf['review_scores_rating'])\n",
    "\n",
    "# replace the old columns with our new one-hot encoded ones\n",
    "data_sf = pd.concat((data_sf.drop([\\\n",
    "    'property_type', 'room_type', 'bed_type', 'review_scores_rating'], axis=1), \\\n",
    "    property_dummies.astype(int), \\\n",
    "    room_dummies.astype(int), bed_dummies.astype(int), ratings_scores_dummies.astype(int)), \\\n",
    "    axis=1)\n",
    "\n",
    "# do same for NYC\n",
    "zipcode_dummies = pd.get_dummies(data_nyc['zipcode'])\n",
    "property_dummies = pd.get_dummies(data_nyc['property_type'])\n",
    "room_dummies = pd.get_dummies(data_nyc['room_type'])\n",
    "bed_dummies = pd.get_dummies(data_nyc['bed_type'])\n",
    "ratings_scores_dummies = pd.get_dummies(data_nyc['review_scores_rating'])\n",
    "# replace the old columns with our new one-hot encoded ones\n",
    "data_nyc = pd.concat((data_nyc.drop(['zipcode',\\\n",
    "    'property_type', 'room_type', 'bed_type', 'review_scores_rating'], axis=1), \\\n",
    "    zipcode_dummies.astype(int),property_dummies.astype(int), \\\n",
    "    room_dummies.astype(int), bed_dummies.astype(int), ratings_scores_dummies.astype(int)), \\\n",
    "    axis=1)\n",
    "\n",
    "# change \"t\" and \"f\" so it reads 1 and 0\n",
    "data_sf[['host_is_superhost', 'host_has_profile_pic', 'host_identity_verified']] = (data_sf[['host_is_superhost', 'host_has_profile_pic', 'host_identity_verified']] == 't').astype(int)\n",
    "data_nyc[['host_is_superhost', 'host_has_profile_pic', 'host_identity_verified']] = (data_nyc[['host_is_superhost', 'host_has_profile_pic', 'host_identity_verified']] == 't').astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len of NYC is:  36760\n",
      "Len of SF is:  6293\n"
     ]
    }
   ],
   "source": [
    "# commute_time_mins, sentiment_score, poverty_percent\n",
    "\n",
    "# INCLUDING the extra three columns\n",
    "# data_sf = data_sf[['host_is_superhost', 'host_has_profile_pic', 'host_identity_verified', \\\n",
    "#        'accommodates', 'bathrooms', 'bedrooms', 'beds', 'security_deposit', \n",
    "#        'cleaning_fee', 'guests_included', 'number_of_reviews', 'Aparthotel',\\\n",
    "#        'Apartment', 'Bed and breakfast', 'Boutique hotel', 'Bungalow', 'Cabin',\\\n",
    "#        'Castle', 'Condominium', 'Cottage', 'Dome house', 'Earth house',\\\n",
    "#        'Guest suite', 'Guesthouse', 'Hostel', 'Hotel', 'House', 'Loft',\\\n",
    "#        'Other', 'Resort', 'Serviced apartment', 'Tiny house', 'Townhouse',\\\n",
    "#        'Villa', 'Entire home/apt', 'Hotel room', 'Private room', 'Shared room',\\\n",
    "#        'Airbed', 'Couch', 'Futon', 'Real Bed', 'commute_time_mins','sentiment_score','poverty_percent']]\n",
    "\n",
    "data_sf.drop(['host_since'], axis=1)\n",
    "# Drop last three cols\n",
    "data_nyc = data_nyc.drop(['host_since', 'avg_income', 'commute_time_mins', 'sentiment_score','poverty_percent'], axis=1)\n",
    "# Retain last three cols\n",
    "#data_nyc = data_nyc.drop(['host_since', 'avg_income'], axis=1)\n",
    "\n",
    "# Uncomment this if testing on SF\n",
    "# data_nyc = data_nyc[['host_is_superhost', 'host_has_profile_pic', 'host_identity_verified', \\\n",
    "#        'accommodates', 'bathrooms', 'bedrooms', 'beds', 'security_deposit', \n",
    "#        'cleaning_fee', 'guests_included', 'number_of_reviews', 'Aparthotel',\\\n",
    "#        'Apartment', 'Bed and breakfast', 'Boutique hotel', 'Bungalow', 'Cabin',\\\n",
    "#        'Castle', 'Condominium', 'Cottage', 'Dome house', 'Earth house',\\\n",
    "#        'Guest suite', 'Guesthouse', 'Hostel', 'Hotel', 'House', 'Loft',\\\n",
    "#        'Other', 'Resort', 'Serviced apartment', 'Tiny house', 'Townhouse',\\\n",
    "#        'Villa', 'Entire home/apt', 'Hotel room', 'Private room', 'Shared room',\\\n",
    "#        'Airbed', 'Couch', 'Futon', 'Real Bed', 'commute_time_mins','sentiment_score','poverty_percent']]\n",
    "\n",
    "# EXCLUDING those three columns (comment out if you want to include them)\n",
    "# data_sf = data_sf[['host_is_superhost', 'host_has_profile_pic', 'host_identity_verified', \\\n",
    "#        'accommodates', 'bathrooms', 'bedrooms', 'beds', 'security_deposit', \n",
    "#        'cleaning_fee', 'guests_included', 'number_of_reviews', 'Aparthotel',\\\n",
    "#        'Apartment', 'Bed and breakfast', 'Boutique hotel', 'Bungalow', 'Cabin',\\\n",
    "#        'Castle', 'Condominium', 'Cottage', 'Dome house', 'Earth house',\\\n",
    "#        'Guest suite', 'Guesthouse', 'Hostel', 'Hotel', 'House', 'Loft',\\\n",
    "#        'Other', 'Resort', 'Serviced apartment', 'Tiny house', 'Townhouse',\\\n",
    "#        'Villa', 'Entire home/apt', 'Hotel room', 'Private room', 'Shared room',\\\n",
    "#        'Airbed', 'Couch', 'Futon', 'Real Bed']]\n",
    "\n",
    "# data_nyc = data_nyc[['host_is_superhost', 'host_has_profile_pic', 'host_identity_verified', \\\n",
    "#        'accommodates', 'bathrooms', 'bedrooms', 'beds', 'security_deposit', \n",
    "#        'cleaning_fee', 'guests_included', 'number_of_reviews', 'Aparthotel',\\\n",
    "#        'Apartment', 'Bed and breakfast', 'Boutique hotel', 'Bungalow', 'Cabin',\\\n",
    "#        'Castle', 'Condominium', 'Cottage', 'Dome house', 'Earth house',\\\n",
    "#        'Guest suite', 'Guesthouse', 'Hostel', 'Hotel', 'House', 'Loft',\\\n",
    "#        'Other', 'Resort', 'Serviced apartment', 'Tiny house', 'Townhouse',\\\n",
    "#        'Villa', 'Entire home/apt', 'Hotel room', 'Private room', 'Shared room',\\\n",
    "#        'Airbed', 'Couch', 'Futon', 'Real Bed']]\n",
    "\n",
    "print(\"Len of NYC is: \", len(data_nyc))\n",
    "print(\"Len of SF is: \", len(data_sf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test len  245\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '6 years'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-f93645e2b400>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m# Predict on SF data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mpredictions_sf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_sf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# Predict on NYC data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    219\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m         \"\"\"\n\u001b[1;32m--> 221\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[0m_preprocess_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    202\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"coef_\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'csc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'coo'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m         return safe_sparse_dot(X, self.coef_.T,\n\u001b[0;32m    206\u001b[0m                                dense_output=True) + self.intercept_\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    534\u001b[0m         \u001b[1;31m# make sure we actually converted to numeric:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    535\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdtype_numeric\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"O\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 536\u001b[1;33m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    537\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    538\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '6 years'"
     ]
    }
   ],
   "source": [
    "# Split into train and test (split off 30% for test set)\n",
    "percent_test = 0.3\n",
    "X_train_sf, X_test_sf, y_train_sf, y_test_sf = train_test_split(data_sf, y_sf, test_size=percent_test, \n",
    "                                                    random_state=1) \n",
    "\n",
    "# Split into train and test (split off 30% for test set)\n",
    "percent_test = 0.3\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_nyc, y_nyc, test_size=percent_test, \n",
    "                                                    random_state=1) \n",
    "\n",
    "# create linear regression object\n",
    "reg = linear_model.LinearRegression() \n",
    "\n",
    "# Train on NYC data\n",
    "print(\"X_test len \", len(X_test.columns))\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict on SF data\n",
    "predictions_sf = reg.predict(X_test_sf)\n",
    "\n",
    "# Predict on NYC data\n",
    "predictions = reg.predict(X_test)\n",
    "\n",
    "# NYC\n",
    "print(\"Mean Square Error: \", mean_squared_error(y_test, predictions))\n",
    "print(\"Mean Absolute Error: \", mean_absolute_error(y_test, predictions))\n",
    "print(\"R^2 Error: \", r2_score(y_test, predictions))\n",
    "\n",
    "# SF\n",
    "print(\"Mean Square Error: \", mean_squared_error(y_test_sf, predictions_sf))\n",
    "print(\"Mean Absolute Error: \", mean_absolute_error(y_test_sf, predictions_sf))\n",
    "print(\"R^2 Error: \", r2_score(y_test_sf, predictions_sf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the residual error\n",
    "\n",
    "# setting plot style\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "# plot residiual errors in training data\n",
    "plt.scatter(reg.predict(X_train), reg.predict(X_train) - y_train, color='green', s=10, label='Train data')\n",
    "\n",
    "# plot residual errors in test data\n",
    "plt.scatter(reg.predict(X_test), reg.predict(X_test) - y_test, color='blue', s=10, label='Test data')\n",
    "\n",
    "# plot line for zero residual error\n",
    "plt.hlines(y=0, xmin=0, xmax=10, linewidth=2)\n",
    "\n",
    "# plot legend\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('prediction')\n",
    "plt.ylabel('error')\n",
    "\n",
    "# plot title\n",
    "plt.title(\"Residual errors\")\n",
    "\n",
    "# function to show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
